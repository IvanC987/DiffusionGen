<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Help - Diffusion Model</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
    <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
</head>
<body>
    <div class="help-container">
        <header>
            <h1><i class="fas fa-question-circle"></i> Help & Documentation</h1>
            <p>Your guide to understanding settings and prompt creation.</p>
        </header>
        <br>
        <div class="card">
            <h2><i class="fas fa-cogs"></i> Basic Settings</h2>
            <ul>
                <li><strong>Prompt:</strong> Enter a descriptive text to guide image generation.</li>
                <li><strong>CFG Scale:</strong> Controls how strictly the model follows the input prompt.
                    <ul>
                        <li>Lower values (1-4) allow more randomness.</li>
                        <li>Higher values (7-12) make the model adhere strictly to the prompt.</li>
                    </ul>
                </li>
                <li><strong>Batch Size:</strong> Number of images generated per request.</li>
                <li><strong>Denoising Steps:</strong> Number of noise-removal iterations.
                    <ul>
                        <li><strong>DDPM:</strong> Recommended: <strong>1000</strong> steps.</li>
                        <li><strong>DDIM:</strong> Recommended: <strong>5-10</strong> steps.</li>
                    </ul>
                </li>
            </ul>
        </div>
        <br>
        <div class="card">
            <h2><i class="fas fa-sliders-h"></i> Advanced Settings</h2>
            <ul>
                <li><strong>Sampling Method:</strong>
                    <ul>
                        <li><strong>DDIM:</strong> Faster sampling, fewer steps.</li>
                        <li><strong>DDPM:</strong> More stable, requires more steps.</li>
                    </ul>
                </li>
                <li><strong>Real-ESRGAN:</strong> Upscaling for sharper images.
                    <ul>
                        <li><strong>No Upscaling:</strong> Resolution stays the same (128x128).</li>
                        <li><strong>2x Upscaling:</strong> Doubles resolution.</li>
                        <li><strong>4x Upscaling:</strong> Quadruples resolution.</li>
                    </ul>
                </li>
                <li><strong>Real-Time Denoising:</strong> View denoising progress at each step. Intermediate images will be saved in `DiffusionGen\inference\flask_outputs\denoising_temp` and compiled video will be saved in `DiffusionGen\inference\flask_outputs\denoising_outputs`</li>
            </ul>
        </div>
        <br>
        <div class="card">
            <h2><i class="fas fa-image"></i> Image Modifications</h2>
            <ul>
                <li><strong>Upload Image (img2img):</strong> Modify an uploaded image.</li>
                <li><strong>Strength (img2img):</strong> Affects how much AI modifies the input.
                    <ul>
                        <li>Lower Value == More Adjustments and vice versa</li>
                    </ul>
                </li>
                <li><strong>Upload Mask (Inpainting):</strong> Selective editing within masked areas.</li>
            </ul>
        </div>
        <br>
        <div class="card">
            <h2><i class="fas fa-random"></i> Random Prompt Generator</h2>
            <p>Generate AI-generated prompts for inspiration.</p>
            <ul>
                <li>Select a category (e.g., <em>Animals, Humans, Scenery</em>).</li>
                <li>Click <strong>Generate Random Prompt</strong>.</li>
                <li>Can choose to use either prompts used in training (default) or completely new prompts that model has not seen before</li>
            </ul>
        </div>
        <br>
        <div class="card">
            <h2><i class="fas fa-lightbulb"></i> Prompt Creation Tips</h2>
            <ol>
                <li><strong>Use Keywords:</strong> Stick to known model words.</li>
                <li><strong>Structured Descriptions:</strong> Use Stable Diffusion-style formatting.</li>
                <li><strong>Balance Specificity:</strong> Avoid overly complex descriptions.</li>
                <li><strong>Use Sensory Details:</strong> Mention lighting, moods, textures.</li>
            </ol>
        </div>

        <br>
        <p><strong>A few things to note:</strong></p>
        <ul>
            <li><strong>Frontend Design:</strong> My HTML/CSS skills are mediocre at best, so pardon the terrible frontend design on some parts. (Most of the HTML/CSS/JS actually came from GPT üòÖ)</li>
            <li><strong>Dark Mode:</strong> It doesn‚Äôt look great‚Äîwouldn‚Äôt recommend using it.</li>
            <li><strong>Category Checkboxes:</strong> For some reason, they are extremely stubborn. I tried multiple times but couldn‚Äôt get them to align properly.</li>
            <li><strong>CFG Limitations:</strong> Doesn‚Äôt quite work as expected due to the limited dataset size (fixed at 4.5 during training).</li>
            <li><strong>Removing Uploaded Image/Mask:</strong> I wanted to add a button for this, but it didn‚Äôt quite work. As a workaround, just click ‚ÄúChoose File‚Äù and immediately cancel to remove.</li>
        </ul>

        <p>...And the list goes on...oh well. ¬Ø\_(„ÉÑ)_/¬Ø (More is noted on the README.md file in repo)</p>

        <p>Have fun!</p>

        <button onclick="window.history.back();" class="back-btn"><i class="fas fa-arrow-left"></i> Back</button>
    </div>
</body>
</html>
